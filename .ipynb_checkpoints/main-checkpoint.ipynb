{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    '''this method is used to convert a given text to tokens by changing all letters to lowercase letters\n",
    "        and remove numbers. It also ignores words containing numbers'''\n",
    "    tokens = []\n",
    "    for line in text:\n",
    "        tokens += [token for token in re.split('[^a-zA-Z0-9]', line.lower()) if\n",
    "                    not re.search('[0-9]', token)] # to perform tokenization on non-alphanumeric words, to remove empty words from the list, to ignore words containing numbers \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "all_words = []\n",
    "\n",
    "class WordDictionary:\n",
    "    #first we define a constructor to initialize our variables\n",
    "    def __init__(self):\n",
    "        self.wordIDs = {} #dict for all word ids\n",
    "        self.currWordId = 1 #start with id 1 for words\n",
    "        self.stemmer = PorterStemmer() #initalize stemmer obj\n",
    "\n",
    "    def appendWord(self, word):\n",
    "        stemWord = self.stemmer.stem(word) #setup the stem word\n",
    "        if stemWord not in self.wordIDs: #check if the dict contains the word\n",
    "            self.wordIDs[stemWord] = self.currWordId #if the word is not present we add the word to the dict along with the id\n",
    "            self.currWordId += 1 #increment the id for the next word\n",
    "\n",
    "    def getWordId(self, word):\n",
    "        stemWord = self.stemmer.stem(word)#getting the stemmed form of the given word\n",
    "        return self.wordIDs.get(stemWord, None)#returning the ID of the stemmef word\n",
    "    \n",
    "    def fetch_d(self):#this method will be used in main.py to fetch all ids that will be written to the output file\n",
    "        return self.wordIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = './ft911/'\n",
    "all_file_names = []\n",
    "\n",
    "class FileDictionary:\n",
    "    #similar to WordDictionary we do the initialize step\n",
    "    def __init__(self, path):\n",
    "        self.fileIDs = {} #dict for all file ids\n",
    "        self.currFileId = 1#start with id 1 for files\n",
    "        self.folder = path#set a foldder ref with the given path\n",
    "\n",
    "    def getFileId(self, file):\n",
    "        return self.fileIDs.get(file, None)#return the ID of the file(DOCNO) for a given file\n",
    "    \n",
    "    def getAllFiles(self):\n",
    "        return self.fileIDs#returns all the files(DOCNOS)\n",
    "    \n",
    "    \n",
    "    def appendFiles(self, file):\n",
    "         self.fileIDs[file] = self.currFileId#appending the file(docno) along with a new id\n",
    "         self.currFileId += 1#incrementing the id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.dom.minidom as xdm\n",
    "\n",
    "date = 'DATE'\n",
    "pro = 'PROFILE'\n",
    "DOC = 'DOCNO'\n",
    "path = './ft911/'\n",
    "doc_tag = ['<DOC>', '</DOC>']\n",
    "read_mode = 'r'\n",
    "\n",
    "class TextParser(object):\n",
    "    def convert(val):#method will be used by the fetchdocs() method below to fetch all docnos and complete data\n",
    "        doc = xdm.parseString(val)#using xdm library to manipulate/parse the input files\n",
    "        root = doc.documentElement#gets the root element\n",
    "        docs = {}#declaring a dict to store all data\n",
    "\n",
    "        for doc in root.childNodes:#iterating through all docs\n",
    "            for ele in doc.childNodes:#iiterating through all elements in docs\n",
    "                if(ele.nodeType == ele.ELEMENT_NODE):#check if the nodetype of the element is node element itself\n",
    "                    if ele.tagName == date or ele.tagName == pro:#ignoring all elements that are not docno\n",
    "                        continue\n",
    "                    elif ele.tagName == DOC:#if the element is docno then we add it to out dict\n",
    "                        DOCNO = ele.firstChild.data.strip()\n",
    "                        docs[DOCNO] = []\n",
    "                    else:#else we append all the data to that specific docno\n",
    "                        docs[DOCNO].append(ele.firstChild.data.strip())\n",
    "        return docs\n",
    "    \n",
    "    \n",
    "    def fetchDocs(file):#this method will be used in main.py to get the parsed docnos and doc content\n",
    "        with open(os.path.join(path, file), read_mode) as File:\n",
    "            doc_data = File.read()\n",
    "        full_doc_data = doc_tag[0] + doc_data + doc_tag[1]\n",
    "        docs = TextParser.convert(full_doc_data)\n",
    "        return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running code at: 2024-03-07 22:51:17.710970\n",
      "Parser output- Success: Writing data COmpleted!\n",
      "Parser output- Success: Writing data COmpleted!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from WordDictionary import WordDictionary\n",
    "from FileDictionary import FileDictionary\n",
    "from tokenizer import tokenizer\n",
    "from DocParser import TextParser\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"Running code at:\", datetime.now())\n",
    "\n",
    "path = \"./ft911/\"\n",
    "folder = os.listdir(path=path)\n",
    "\n",
    "parser_file = \"parser_output.txt\"\n",
    "w = 'w'\n",
    "a = 'a'\n",
    "\n",
    "def parser_output(data, mode):    \n",
    "    try:#exception handling\n",
    "        # filePath = os.path.join(Path(__file__).parent.resolve(), parser_file)#created a file if it doesn't already exist to write output\n",
    "        # with open(filePath, mode) as parser_output:\n",
    "        with open(parser_file, \"w\") as parser_output:\n",
    "            for key in sorted(data.keys()):#iterates through all docnos and stemmed words\n",
    "                parser_output.write(f\"{key}\\t{data[key]}\\n\")#appeninf the DOCNO: DOCID and Word : WOrdID to the parser_output file\n",
    "        print(\"Parser output- Success: Writing data COmpleted!\")\n",
    "    except Exception as e:#shows error message in case of failure\n",
    "        print(\"Parser output- Failure: error while uploading data\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "#then we initialize our custom dictionaries\n",
    "WordDict = WordDictionary()\n",
    "FileDict = FileDictionary(path)\n",
    "\n",
    "#looping over all the files in the folder mentioned above and and adding them to complete data\n",
    "for file in folder:\n",
    "    docs = TextParser.fetchDocs(file)\n",
    "    for docno, data in docs.items():\n",
    "        FileDict.appendFiles(docno)\n",
    "        tokens = tokenizer(data)\n",
    "        for token in tokens:\n",
    "            WordDict.appendWord(token)\n",
    "\n",
    "parser_output(WordDict.fetch_d(), w)#once all the word data is feteched, we write the data to the output file using the 'w' mode\n",
    "parser_output(FileDict.getAllFiles(), a)#once all the filenames are feteched, we append the data to the output file using the 'a' mode\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
